{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e830067-6bfc-4a18-9d7f-14aa28e5bcb2",
   "metadata": {},
   "source": [
    "\n",
    "Based on https://www.frontiersin.org/journals/immunology/articles/10.3389/fimmu.2021.640725/full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80733f84-2537-4d86-91e3-e7285d707c6e",
   "metadata": {},
   "source": [
    "The rationale for the Over Amplification Rate measure\n",
    "Since out-of-frame TCR/BCR rearrangements do not form a functional receptor, they are not subjected to any specific clonal expansions and selection (Murugan et al., 2012). Being a passenger genomic variation, they change their initial (recombinational) clonal frequencies just randomly following the frequency changes of the second functional (in-frame) TCR/BCR allele present in the same T/B cell clone. According to the TCR/BCR loci rearrangement mechanism, the formation of in-frame and out-of-frame allele combinations in the same cell is also a stochastic and independent process in terms of V- and J-genes frequency. It leads to the conclusion that V- and J-gene frequencies among out-of-frame rearrangements must be sufficiently stable and must be equal to the initial recombination frequencies despite repertoire changes caused by various immune challenges (Figure 1). Thus, reproducible deviation of out-of-frame V- and J-gene frequencies (for the same multiplex PCR primer set) from the initial recombinational frequencies observed in the sequenced repertoire dataset is a result of artificial aberration caused by PCR amplification rather than immune repertoire evolution. Thus out-of-frame clonotypes can be considered a natural calibrator that can be used to measure amplification bias and quantitatively correct immune repertoire data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f21b4b-2d04-4541-9d33-ec49a61822ad",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be45912-ec6e-449d-8b5e-dfdc49157fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8911290-04d7-456b-aa75-07cbb28647e4",
   "metadata": {},
   "source": [
    "# Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3c556c-9d4f-4ca2-8e46-5f13d19b2428",
   "metadata": {},
   "outputs": [],
   "source": [
    "## multiplex, without UMI\n",
    "\n",
    "path = '/home/mgikalo/projects/rnrmu_p1/cfse1_reanalyze/mixcr/p1-KRAS-1-mut-CD8-CFSElo-beta-chain.clones_TRB.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad588c7-837e-4817-97b7-9780e23ff9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(path, sep='\\t')\n",
    "\n",
    "# transform V- and J-segments format\n",
    "\n",
    "df1['Vsegm'] = [x.split('*')[0] for x in df1.allVHitsWithScore]\n",
    "df1['Jsegm'] = [x.split('*')[0] for x in df1.allJHitsWithScore]\n",
    "\n",
    "# leave only necessary columns in df\n",
    "df1 = df1[['aaSeqCDR3', 'nSeqCDR3', 'Vsegm', 'Jsegm', 'readCount']]\n",
    "\n",
    "# manage duplicates\n",
    "df1 = df1.groupby(['aaSeqCDR3', 'nSeqCDR3', 'Vsegm', 'Jsegm'], as_index=False)\\\n",
    "                .agg({'readCount' : 'sum'})\\\n",
    "                .sort_values('readCount', ascending=False)\\\n",
    "                .reset_index(drop=True)\n",
    "\n",
    "# remove all clonotypes having 1 read\n",
    "# because of this:\n",
    "# \"1.8 (for MPlex) and 2.5 (for RACE) reads per out-of-frame clonotype are a minimal sufficient sequencing coverage to get adequate OAR values with an acceptable error rate of ~10%\"\n",
    "df1 = df1.loc[df1.readCount>1]\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2e7849-2b20-4477-af97-11cb4092fd47",
   "metadata": {},
   "source": [
    "# Select non-functional clonotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79f6d3f-2fc2-4359-ad26-8324056ec321",
   "metadata": {},
   "outputs": [],
   "source": [
    "## All clonotypes\n",
    "len([x for x in df1.aaSeqCDR3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c02f8b-7ca3-4569-9d15-58e577f23346",
   "metadata": {},
   "outputs": [],
   "source": [
    "## functional clonotypes\n",
    "len([x for x in df1.aaSeqCDR3 if x.isalpha()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5aa714-2f03-4575-b5fe-92164e2d4790",
   "metadata": {},
   "outputs": [],
   "source": [
    "## non-functional clonotypes\n",
    "non_f = [x for x in df1.aaSeqCDR3 if x.isalpha()==0]\n",
    "len([x for x in df1.aaSeqCDR3 if x.isalpha()==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decbaf1b-87f2-41f5-80bb-0176849408a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## how many non-functional clonotypes in each V-segment?\n",
    "df1.loc[df1.aaSeqCDR3.isin(non_f)]\\\n",
    "        .groupby('Vsegm').agg({'aaSeqCDR3' : 'count'})\\\n",
    "        .sort_values('aaSeqCDR3', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f01524c-35a9-494f-be1b-07d1e79116aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## how many non-functional clonotypes in each J-segment?\n",
    "df1.loc[df1.aaSeqCDR3.isin(non_f)]\\\n",
    "        .groupby('Jsegm').agg({'aaSeqCDR3' : 'count'})\\\n",
    "        .sort_values('aaSeqCDR3', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0812db1a-b0a9-4426-b8f0-958d70ee965d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## df for non-func clonotypes\n",
    "df_nf = df1.loc[df1.aaSeqCDR3.isin(non_f)].sort_values('readCount').reset_index(drop=True)\n",
    "\n",
    "## Discard the most abundant non-functional clonotype\n",
    "df_nf = df_nf.iloc[:-1]\n",
    "df_nf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a029d7b6-354f-4644-8ea9-79976daf6b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "## df for func clonotypes\n",
    "df_f = df1.loc[~df1.aaSeqCDR3.isin(non_f)].sort_values('readCount').reset_index(drop=True)\n",
    "df_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a887b02-33b4-47ea-8b8a-311182e2959f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = df1[['aaSeqCDR3', 'nSeqCDR3', 'readCount']].loc[~df1.aaSeqCDR3.isin(non_f)].nSeqCDR3.to_list()\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab3a5d9-ec59-4a46-a60b-81b84d70e405",
   "metadata": {},
   "source": [
    "# Search for in-frame/out of frame pairs with Levenstein distance == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28aa36d-791c-44a4-87ea-f5655072a8b1",
   "metadata": {},
   "source": [
    "Search for in-frame and out-of-frame clone pairs which differ by one indel (Levenshtein distance = 1).\n",
    "If their ratio is less than 1:500, the smaller clone in pair is discarded, and its count is added to the count of the larger clone\n",
    "(this procedure guarantees to discard most sequencing errors present in 1 per 1000 nucleotides average)\n",
    "* предлагаю пренебречь прибавлением каунтов для сокращения вычислений"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebaddfd4-430a-474c-88d6-65c2142c920a",
   "metadata": {},
   "source": [
    "## Levenstein distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63182336-bfac-47c5-a186-02235f0d89c3",
   "metadata": {},
   "source": [
    "https://blog.paperspace.com/implementing-levenshtein-distance-word-autocomplete-autocorrect/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d175fdb-5c8c-4ebb-9ec8-fab204fe11af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshteinDistanceDP(token1, token2):\n",
    "    distances = np.zeros((len(token1) + 1, len(token2) + 1))\n",
    "\n",
    "    for t1 in range(len(token1) + 1):\n",
    "        distances[t1][0] = t1\n",
    "\n",
    "    for t2 in range(len(token2) + 1):\n",
    "        distances[0][t2] = t2\n",
    "        \n",
    "    a = 0\n",
    "    b = 0\n",
    "    c = 0\n",
    "    \n",
    "    for t1 in range(1, len(token1) + 1):\n",
    "        for t2 in range(1, len(token2) + 1):\n",
    "            if (token1[t1-1] == token2[t2-1]):\n",
    "                distances[t1][t2] = distances[t1 - 1][t2 - 1]\n",
    "            else:\n",
    "                a = distances[t1][t2 - 1]\n",
    "                b = distances[t1 - 1][t2]\n",
    "                c = distances[t1 - 1][t2 - 1]\n",
    "                \n",
    "                if (a <= b and a <= c):\n",
    "                    distances[t1][t2] = a + 1\n",
    "                elif (b <= a and b <= c):\n",
    "                    distances[t1][t2] = b + 1\n",
    "                else:\n",
    "                    distances[t1][t2] = c + 1\n",
    "\n",
    "    #printDistances(distances, len(token1), len(token2))\n",
    "    return distances[len(token1)][len(token2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b58c7c-39b8-44e2-a1f6-c262956ffc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## split the df into functional and non-functional\n",
    "## calculate levenstein distances\n",
    "## if levenstein distance == 1 :\n",
    "# compare redCounts\n",
    "# if readCount > 1:500 : delete row in non-func and add it's readCount to the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899a99b5-2d91-4739-b3d5-854449c29d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df_nf.iterrows():\n",
    "    for j, rw in df_f.iterrows():\n",
    "        if levenshteinDistanceDP(row.nSeqCDR3, rw.nSeqCDR3) == 1:\n",
    "            if row.readCount / rw.readCount > 500:\n",
    "                df_f = df_f.drop(j)\n",
    "                row.readCount += rw.readCount\n",
    "            elif rw.readCount / row.readCount > 500:\n",
    "                df_nf = df_nf.drop(i)\n",
    "                rw.readCount += row.readCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc6db8a-43b9-4df7-950d-1664f6ea62df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## assign 0 to func and 1 to non-func clonotypes\n",
    "df_nf['is_nf'] = 1\n",
    "df_f['is_nf'] = 0\n",
    "\n",
    "## join dfs\n",
    "df = pd.concat([df_f, df_nf]).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d35093-b5ae-4a39-a4ef-7f03343f9633",
   "metadata": {},
   "source": [
    "# Calculate OARs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b57808-19b5-496c-bb6f-47dafe5e67ca",
   "metadata": {},
   "source": [
    "## For V-segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad1a204-0a11-449d-bae2-8f65a6382652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate OAR for each V-segment\n",
    "dfv = df.query('is_nf==1')\\\n",
    "        .groupby('Vsegm', as_index=False).agg({'is_nf' : 'sum', 'readCount' : 'sum'})\\\n",
    "        .rename(columns={'is_nf' : 'nonfunc_clones'})\n",
    "dfv['oar_v'] = (dfv.readCount / dfv.readCount.sum()) / (dfv.nonfunc_clones / dfv.nonfunc_clones.sum())\n",
    "dfv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a600778-83c5-4b3e-8dfb-153b82d1c350",
   "metadata": {},
   "source": [
    "## For J-segment (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c478437-db99-439f-893a-69ba9523021a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate OAR for each J-segment\n",
    "dfj = df.query('is_nf==1')\\\n",
    "        .groupby('Jsegm', as_index=False).agg({'is_nf' : 'sum', 'readCount' : 'sum'})\\\n",
    "        .rename(columns={'is_nf' : 'nonfunc_clones'})\n",
    "dfj['oar_j'] = (dfj.readCount / dfj.readCount.sum()) / (dfj.nonfunc_clones / dfj.nonfunc_clones.sum())\n",
    "dfj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87714517-8a2a-435f-86e8-959ae12b7fad",
   "metadata": {},
   "source": [
    "## Total OAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f40648-1594-4db7-976f-78c6aa263f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add OARs for V- and J- to main df\n",
    "df = df.merge(dfv[['Vsegm', 'oar_v']], how='left', on='Vsegm')\\\n",
    "        .merge(dfj[['Jsegm', 'oar_j']], how='left', on='Jsegm')\n",
    "\n",
    "## if no OAR was calculated for V- or J- replace with 1\n",
    "df = df.fillna(1)\n",
    "\n",
    "# calculate the overall OAR for each VJ pair\n",
    "df['oar'] = df.oar_v * df.oar_j\n",
    "\n",
    "# calculate adjusted read counts\n",
    "df['readCount_adj'] = df.readCount / df.oar\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81e2f98-9b58-4efd-bbfe-7be1528ebc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "by_v = df.groupby('Vsegm', as_index=False).agg({'oar_v' : 'mean'})\n",
    "by_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80b82d7-a8e4-411a-8faf-1f51d11c61ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(16, 6)})\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.barplot(data=by_v, x='Vsegm', y='oar_v', color='grey')\n",
    "plt.xticks(rotation=30)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f006c7ef-8a83-4dc0-9641-83a0e05388f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "by_j = df.groupby('Jsegm', as_index=False).agg({'oar_j' : 'mean'})\n",
    "by_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0a4545-88e2-4a17-9488-2183ace82589",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(10, 4)})\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.barplot(data=by_j, x='Jsegm', y='oar_j', color='grey')\n",
    "plt.xticks(rotation=30)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006222fb-6148-4f67-9733-5ec66ea3747a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94025b2d-9114-4346-b685-c96069dbe4c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-main]",
   "language": "python",
   "name": "conda-env-.conda-main-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
